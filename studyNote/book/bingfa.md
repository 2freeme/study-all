# 并发编程

1. ### 并发编程的挑战

   - ##### 上下文切换

     - 即使是单核处理器也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现
       这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切
       换线程执行，让我们感觉多个线程是同时执行的，时间片一般是几十毫秒（ms）。
       CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个
       任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这
       个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。
     - 这样子看来其实多线程多了上下文的切换，其实不一定比单线程快，这个也在实战中得到见证![image-20210126102229735](D:\MyData\dingpf1\AppData\Roaming\Typora\typora-user-images\image-20210126102229735.png)
     - 减少上下文的切换
       - 并发加锁
       - CAS算法
       - 使用最少线程
       - 协程线程

   - ##### 死锁

     - 一旦发生了死锁的话，会造成资源的等待和不可用
     - 避免死锁
       - 避免一个线程同时获取多个锁。
       - 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
       - 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。
       - 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。

   - ##### 资源限制挑战

     - 资源限制就是指，在并发编程中，执行的资源受计算机的硬件和软件的资源限制，比如带宽和IO，举个例子：带宽 2M/s，一个线程能1M/S ,即使开10个线程也不会变成 10M/S。所以在进行并发编程时，要考虑这些资源的限制。硬件资源限制有带宽的上传/下载速度、硬盘读写速度和CPU的处理速度。软件资源限制有数据库的连接数和socket连接数等。

     - 资源限制引发的问题：如果资源限制了，依旧是用多线程去跑，将串行改变成并行，会平白无故的增加上下文的切换和资源的调度。

     - 如何解决资源限制：硬件：增加硬件资源。软件：将资源复用，使用连接池。

     - 资源限制下的编程：如何在资源限制的情况下，让程序执行得更快呢？方法就是，根据不同的资源限制调整程序的并发度，比如下载文件程序依赖于两个资源——带宽和硬盘读写速度。有数据库操作时，涉及数据库连接数，如果SQL语句执行非常快，而线程的数量比数据库连接数大很多，则某些线程会被阻塞，等待数据库连接。

       

2. ### 并发机制的底层实现

   - synchronized
     - synchronized的锁对象：
       - 对于普通同步方法，锁是当前实例对象。
       - 对于静态同步方法，锁是当前类的Class对象。
       - 对于同步方法块，锁是Synchonized括号里配置的对象。

3. ### 线程池

   - ##### 提交任务到线程池

     - 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。
     - 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。
     - 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务
     - <img src="D:\MyData\dingpf1\AppData\Roaming\Typora\typora-user-images\image-20210126144436798.png" alt="image-20210126144436798" style="zoom:50%;" />
     - <img src="D:\MyData\dingpf1\AppData\Roaming\Typora\typora-user-images\image-20210126144653097.png" alt="image-20210126144653097" style="zoom: 50%;" />

   - ThreadPoolExecutor执行execute方法分下面4种情况

     - 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。
     - 如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。
     - 如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。
     - 如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。

   - ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。

   - ##### 线程池的参数

     - corePoolSize
     - runnableTaskQueue 任务队列
       - ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排队
       - LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。
       - SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于Linked-BlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。
       - PriorityBlockingQueue：一个具有优先级的无限阻塞队列。
     - maximumPoolSize ：线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是，如果使用了无界的任务队列这个参数就没什么效果。
     - hreadFactory：用于设置创建线程的工厂。
     - RejectedExecutionHandler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。
       - AbortPolicy：直接抛出异常。
       - CallerRunsPolicy：只用调用者所在线程来运行任务。
       - DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
       - DiscardPolicy：不处理，丢弃掉。
     - keepAliveTime：（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。所以，如果任务很多，并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率。 就是非核心线程。
     - TimeUnit（线程活动保持时间的单位）

   - ##### 线程池提交任务

     - execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。
     - submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

   - ##### 关闭线程池

     - 可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。
     - shutdown

   - ##### 线程池的配置

     - 分析：
       - 任务的性质：CPU密集型任务、IO密集型任务和混合型任务。
       - 任务的优先级：高、中和低。
       - 任务的执行时间：长、中和短。
       - 任务的依赖性：是否依赖其他系统资源，如数据库连接。
       - 性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。由于IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量。如果这两个任务执行时间相差太大，则没必要进行分解。可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。
     - 如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。
     - 执行时间不同的任务可以交给不同规模的线程池来处理，或者可以使用优先级队列，让执行时间短的任务先执行。
     - 依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。
     - 建议使用有界队列。有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点儿，比如几千。但是如果设置成无界队列的话，恰好有很多任务比较慢，在队列中堆的很多很有可能撑爆内存。

   - ##### 线程池的监控

     - 待定。有可视化工具

4. ### Executor框架



